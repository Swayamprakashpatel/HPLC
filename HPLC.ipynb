{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HPLC.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOdkuMv7rtoGJs3+Ixf9lK5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Swayamprakashpatel/HPLC/blob/main/HPLC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "hdOKQlX8nYHN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "623c01f1-09ff-4797-c51a-21e069ae2ecb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pubchempy in /usr/local/lib/python3.7/dist-packages (1.0.4)\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pandas_datareader as web\n",
        "!pip install pubchempy\n",
        "import pubchempy as pcp\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from google.colab import files\n",
        "import time as tm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = pd.read_csv('/content/Data.csv')\n",
        "df1 = pd.DataFrame(df1)\n",
        "df1 = df1.iloc[:,0:25]\n",
        "\n",
        "cidvals = df1['CID_1']\n",
        "componentFingerprint = []\n",
        "for cid in cidvals:\n",
        "  c = pcp.Compound.from_cid(cid)\n",
        "  componentFingerprint.append(c.cactvs_fingerprint)\n",
        "  tm.sleep(0.1)\n",
        "\n",
        "df2 = df1.assign(fp=componentFingerprint)\n",
        "i = 1\n",
        "for  componentFingerprint in c.cactvs_fingerprint:\n",
        "    df2['fp'] = df2['fp'].astype(str)\n",
        "    df2['fp'+str (i)] = df2['fp'].str[i-1:i]\n",
        "    i = i+ 1\n",
        "#print(componentFingerprint)\n",
        "#print(df2)\n",
        "\n",
        "#df2.to_csv('Drug_1.csv')\n",
        "\n",
        "#FOR DRUGS_2\n",
        "\n",
        "cidvals = df1['CID_2']\n",
        "componentFingerprint = []\n",
        "for cid in cidvals:\n",
        "  c = pcp.Compound.from_cid(cid)\n",
        "  componentFingerprint.append(c.cactvs_fingerprint)\n",
        "  tm.sleep(0.1)\n",
        "\n",
        "df3 = df1.assign(fp=componentFingerprint)\n",
        "i = 1\n",
        "for  componentFingerprint in c.cactvs_fingerprint:\n",
        "    df3['fp'] = df3['fp'].astype(str)\n",
        "    df3['fp'+str (i)] = df3['fp'].str[i-1:i]\n",
        "    i = i+ 1\n",
        "#print(componentFingerprint)\n",
        "#print(df2)\n",
        "\n",
        "#df3.to_csv('Drug_1.csv')\n",
        "\n",
        "\n",
        "#INPUT DATA\n",
        "df2 = df2.iloc[:,23:904]\n",
        "df3 = df3.iloc[:,23:904]\n",
        "X = pd.concat([df2,df3], axis = 1)\n",
        "print(X,X.shape)\n",
        "X.head()\n",
        "\n",
        "\n",
        "\n",
        "#Output Data\n",
        "Y1 = df1.iloc[:,4:11]\n",
        "Y1.head()\n",
        "\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "enc = OneHotEncoder(handle_unknown='ignore')\n",
        "\n",
        "enc.fit(Y1)\n",
        "OneHotEncoder(handle_unknown='ignore')\n",
        "enc.categories_\n",
        "\n",
        "Y2 = enc.transform(Y1).toarray() #Categorical Data\n",
        "print(Y2,Y2.shape)\n",
        "\n",
        "Y3 = df1.iloc[:,11:22] #Numerical Data\n",
        "\n"
      ],
      "metadata": {
        "id": "xUYrz-fYpHKK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = pd.read_csv('/content/Data.csv')\n",
        "df1 = df1.values\n",
        "#df1 = df1.iloc[:,0:25]\n",
        "\n",
        "X = pd.read_csv('/content/CID.csv')\n",
        "X = X.values\n",
        "X = X[:,:]\n",
        "\n",
        "\n",
        "Y1 = df1[:,4:11]\n",
        "#Y1.head()\n",
        "\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "enc = OneHotEncoder(handle_unknown='ignore')\n",
        "\n",
        "enc.fit(Y1)\n",
        "OneHotEncoder(handle_unknown='ignore')\n",
        "enc.categories_\n",
        "\n",
        "Y2 = enc.transform(Y1).toarray() #Categorical Data\n",
        "print(Y2,Y2.shape)\n",
        "\n",
        "Y3 = df1[:,11:22] #Numerical Data\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XAyWOfGbutJS",
        "outputId": "6a90f6b9-b48e-45b2-d61e-35f6ab8dc4f7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1. 0. 0. ... 0. 0. 0.]\n",
            " [0. 1. 1. ... 0. 0. 0.]\n",
            " [1. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [1. 0. 1. ... 0. 0. 0.]\n",
            " [1. 0. 0. ... 0. 0. 0.]\n",
            " [0. 1. 1. ... 0. 0. 0.]] (1108, 164)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X,X.shape)\n",
        "\n",
        "print(Y2,Y2.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j5EgX_tMr0_O",
        "outputId": "d93ff1f9-3bcd-4b58-c8f0-b099f02ecc33"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1 1 0 ... 0 0 0]\n",
            " [1 1 0 ... 0 0 0]\n",
            " [1 1 0 ... 0 0 0]\n",
            " ...\n",
            " [1 1 1 ... 0 0 0]\n",
            " [1 1 1 ... 0 0 0]\n",
            " [1 0 0 ... 0 0 0]] (1108, 1762)\n",
            "[[1. 0. 0. ... 0. 0. 0.]\n",
            " [0. 1. 1. ... 0. 0. 0.]\n",
            " [1. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [1. 0. 1. ... 0. 0. 0.]\n",
            " [1. 0. 0. ... 0. 0. 0.]\n",
            " [0. 1. 1. ... 0. 0. 0.]] (1108, 164)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wwoKsdOCsJRT",
        "outputId": "ea608a5a-fba8-4aac-84c8-a810547954e9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1108, 1762)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_val_and_test, Y2_train, Y2_val_and_test = train_test_split(X, Y2, test_size=0.01,random_state = 42 )\n",
        "X_val, X_test, Y2_val, Y2_test = train_test_split(X_val_and_test, Y2_val_and_test, test_size=0.5, random_state= 42)\n",
        "\n",
        "X_train = np.asarray(X_train).astype(np.int64)\n",
        "X_val = np.asarray(X_val).astype(np.int64)\n",
        "X_test = np.asarray(X_test).astype(np.int64)\n",
        "Y2_train = np.asarray(Y2_train).astype(np.int64)\n",
        "Y2_val = np.asarray(Y2_val).astype(np.int64)\n",
        "Y2_test = np.asarray(Y2_test).astype(np.int64)"
      ],
      "metadata": {
        "id": "_c6AzknaMkOr"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime\n",
        "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
      ],
      "metadata": {
        "id": "bl6TPQWc79WI"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#STRATYFY K FOLD\n",
        "\n",
        "output_nodes = Y2.shape[1]\n",
        "from sklearn.model_selection import KFold\n",
        "skf = KFold(n_splits=5 , shuffle=False)\n",
        "for train, val in skf.split(X, Y2):\n",
        "\n",
        "  filepath = '/content/drive/MyDrive/Model_DE/Model.hdf5'\n",
        " \n",
        "  checkpoint = [tf.keras.callbacks.ModelCheckpoint(filepath, monitor='val_accuracy', mode='max', save_best_only=True, Save_weights_only = False, verbose = 2), \n",
        "              tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=10, verbose =2), [tensorboard_callback]]\n",
        "\n",
        "  model = tf.keras.Sequential([\n",
        "                             tf.keras.layers.Dense(1725, activation='relu', input_shape=(1762,)),\n",
        "                             tf.keras.layers.Dense(1512, activation='relu'),\n",
        "                             tf.keras.layers.Dense(1512, activation='relu'),\n",
        "                             tf.keras.layers.Dense(output_nodes, activation= 'softmax')])\n",
        "  model.compile(optimizer=tf.keras.optimizers.RMSprop(), loss=tf.keras.losses.BinaryCrossentropy(from_logits = False), metrics=['accuracy'])\n",
        "  \n",
        "  hist = model.fit(X[train].astype(np.int64), Y2[train].astype(np.int64), epochs= 2000, callbacks=[checkpoint],validation_data=(X[val].astype(np.int64), Y2[val].astype(np.int64)), batch_size= 100)\n",
        "\n",
        "\n",
        "model.evaluate(X, Y2)\n",
        " \n",
        "Y2_train_predict = np.round(model.predict(X_train))\n",
        "Y2_train_l = tf.argmax(Y2_train, axis = 1)\n",
        "Y2_train_predict_l = tf.argmax(Y2_train_predict, axis =1)\n",
        "import sklearn.metrics as skm\n",
        "cm = skm.multilabel_confusion_matrix(Y2_train_l, Y2_train_predict_l)\n",
        "print(cm)\n",
        "print( skm.classification_report(Y2_train_l, Y2_train_predict_l))\n",
        " \n",
        "train_acc = max(hist.history['accuracy'])\n",
        "val_acc = max(hist.history['val_accuracy'])\n",
        "train_loss = min(hist.history['loss'])\n",
        "val_loss = min(hist.history['val_loss'])\n",
        "print('Training Accuracy is')\n",
        "print(train_acc)\n",
        "print('Validation Accuracy is')\n",
        "print(val_acc)\n",
        "print('Training loss is')\n",
        "print(train_loss)\n",
        "print('Validation loss is')\n",
        "print(val_loss)\n",
        " "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zND67Q1l5nD6",
        "outputId": "77803258-bfe8-4371-d345-0bf594106c71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.2346 - accuracy: 0.0824\n",
            "Epoch 1: val_accuracy improved from -inf to 0.00000, saving model to /content/drive/MyDrive/Model_DE/Model.hdf5\n",
            "9/9 [==============================] - 5s 446ms/step - loss: 0.2346 - accuracy: 0.0824 - val_loss: 0.0731 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/2000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0614 - accuracy: 0.0000e+00\n",
            "Epoch 2: val_accuracy did not improve from 0.00000\n",
            "9/9 [==============================] - 3s 331ms/step - loss: 0.0614 - accuracy: 0.0000e+00 - val_loss: 0.0787 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/2000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0661 - accuracy: 0.0000e+00\n",
            "Epoch 3: val_accuracy did not improve from 0.00000\n",
            "9/9 [==============================] - 2s 245ms/step - loss: 0.0661 - accuracy: 0.0000e+00 - val_loss: 0.0788 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/2000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0683 - accuracy: 0.0000e+00\n",
            "Epoch 4: val_accuracy did not improve from 0.00000\n",
            "9/9 [==============================] - 2s 277ms/step - loss: 0.0683 - accuracy: 0.0000e+00 - val_loss: 0.0763 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/2000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0629 - accuracy: 0.0000e+00\n",
            "Epoch 5: val_accuracy did not improve from 0.00000\n",
            "9/9 [==============================] - 2s 252ms/step - loss: 0.0629 - accuracy: 0.0000e+00 - val_loss: 0.0942 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/2000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0667 - accuracy: 0.0000e+00\n",
            "Epoch 6: val_accuracy did not improve from 0.00000\n",
            "9/9 [==============================] - 2s 252ms/step - loss: 0.0667 - accuracy: 0.0000e+00 - val_loss: 0.0712 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/2000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0593 - accuracy: 0.0000e+00\n",
            "Epoch 7: val_accuracy did not improve from 0.00000\n",
            "9/9 [==============================] - 2s 240ms/step - loss: 0.0593 - accuracy: 0.0000e+00 - val_loss: 0.0756 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/2000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0606 - accuracy: 0.0000e+00\n",
            "Epoch 8: val_accuracy did not improve from 0.00000\n",
            "9/9 [==============================] - 2s 245ms/step - loss: 0.0606 - accuracy: 0.0000e+00 - val_loss: 0.0697 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/2000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0558 - accuracy: 0.0000e+00\n",
            "Epoch 9: val_accuracy did not improve from 0.00000\n",
            "9/9 [==============================] - 2s 231ms/step - loss: 0.0558 - accuracy: 0.0000e+00 - val_loss: 0.0868 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/2000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0537 - accuracy: 0.0000e+00\n",
            "Epoch 10: val_accuracy did not improve from 0.00000\n",
            "9/9 [==============================] - 2s 229ms/step - loss: 0.0537 - accuracy: 0.0000e+00 - val_loss: 0.0756 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/2000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0573 - accuracy: 0.0000e+00\n",
            "Epoch 11: val_accuracy did not improve from 0.00000\n",
            "9/9 [==============================] - 2s 233ms/step - loss: 0.0573 - accuracy: 0.0000e+00 - val_loss: 0.0749 - val_accuracy: 0.0000e+00\n",
            "Epoch 11: early stopping\n",
            "Epoch 1/2000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.2227 - accuracy: 0.0621\n",
            "Epoch 1: val_accuracy improved from -inf to 0.00000, saving model to /content/drive/MyDrive/Model_DE/Model.hdf5\n",
            "9/9 [==============================] - 3s 272ms/step - loss: 0.2227 - accuracy: 0.0621 - val_loss: 0.0617 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/2000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0637 - accuracy: 0.0000e+00\n",
            "Epoch 2: val_accuracy did not improve from 0.00000\n",
            "9/9 [==============================] - 2s 238ms/step - loss: 0.0637 - accuracy: 0.0000e+00 - val_loss: 0.0636 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/2000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0676 - accuracy: 0.0000e+00\n",
            "Epoch 3: val_accuracy did not improve from 0.00000\n",
            "9/9 [==============================] - 2s 234ms/step - loss: 0.0676 - accuracy: 0.0000e+00 - val_loss: 0.0667 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/2000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0683 - accuracy: 0.0000e+00\n",
            "Epoch 4: val_accuracy did not improve from 0.00000\n",
            "9/9 [==============================] - 2s 247ms/step - loss: 0.0683 - accuracy: 0.0000e+00 - val_loss: 0.0681 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/2000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0653 - accuracy: 0.0000e+00\n",
            "Epoch 5: val_accuracy did not improve from 0.00000\n",
            "9/9 [==============================] - 2s 245ms/step - loss: 0.0653 - accuracy: 0.0000e+00 - val_loss: 0.0717 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/2000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0617 - accuracy: 0.0045\n",
            "Epoch 6: val_accuracy did not improve from 0.00000\n",
            "9/9 [==============================] - 2s 234ms/step - loss: 0.0617 - accuracy: 0.0045 - val_loss: 0.0770 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/2000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0651 - accuracy: 0.0011\n",
            "Epoch 7: val_accuracy did not improve from 0.00000\n",
            "9/9 [==============================] - 2s 230ms/step - loss: 0.0651 - accuracy: 0.0011 - val_loss: 0.0648 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/2000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0584 - accuracy: 0.0000e+00\n",
            "Epoch 8: val_accuracy did not improve from 0.00000\n",
            "9/9 [==============================] - 2s 247ms/step - loss: 0.0584 - accuracy: 0.0000e+00 - val_loss: 0.0774 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/2000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0583 - accuracy: 0.0034\n",
            "Epoch 9: val_accuracy did not improve from 0.00000\n",
            "9/9 [==============================] - 2s 250ms/step - loss: 0.0583 - accuracy: 0.0034 - val_loss: 0.0691 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/2000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0578 - accuracy: 0.0090\n",
            "Epoch 10: val_accuracy did not improve from 0.00000\n",
            "9/9 [==============================] - 2s 231ms/step - loss: 0.0578 - accuracy: 0.0090 - val_loss: 0.0661 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/2000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0510 - accuracy: 0.0102\n",
            "Epoch 11: val_accuracy did not improve from 0.00000\n",
            "9/9 [==============================] - 2s 243ms/step - loss: 0.0510 - accuracy: 0.0102 - val_loss: 0.0721 - val_accuracy: 0.0000e+00\n",
            "Epoch 11: early stopping\n",
            "Epoch 1/2000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.2300 - accuracy: 0.1648\n",
            "Epoch 1: val_accuracy improved from -inf to 0.00000, saving model to /content/drive/MyDrive/Model_DE/Model.hdf5\n",
            "9/9 [==============================] - 3s 276ms/step - loss: 0.2300 - accuracy: 0.1648 - val_loss: 0.0610 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/2000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0646 - accuracy: 0.0000e+00\n",
            "Epoch 2: val_accuracy did not improve from 0.00000\n",
            "9/9 [==============================] - 2s 236ms/step - loss: 0.0646 - accuracy: 0.0000e+00 - val_loss: 0.0600 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/2000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0739 - accuracy: 0.0000e+00\n",
            "Epoch 3: val_accuracy did not improve from 0.00000\n",
            "9/9 [==============================] - 2s 230ms/step - loss: 0.0739 - accuracy: 0.0000e+00 - val_loss: 0.0604 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/2000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0643 - accuracy: 0.0000e+00\n",
            "Epoch 4: val_accuracy did not improve from 0.00000\n",
            "9/9 [==============================] - 2s 232ms/step - loss: 0.0643 - accuracy: 0.0000e+00 - val_loss: 0.0687 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/2000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0721 - accuracy: 0.0000e+00\n",
            "Epoch 5: val_accuracy did not improve from 0.00000\n",
            "9/9 [==============================] - 2s 234ms/step - loss: 0.0721 - accuracy: 0.0000e+00 - val_loss: 0.0594 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/2000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0620 - accuracy: 0.0000e+00\n",
            "Epoch 6: val_accuracy did not improve from 0.00000\n",
            "9/9 [==============================] - 2s 224ms/step - loss: 0.0620 - accuracy: 0.0000e+00 - val_loss: 0.0930 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/2000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0718 - accuracy: 0.0000e+00\n",
            "Epoch 7: val_accuracy did not improve from 0.00000\n",
            "9/9 [==============================] - 2s 235ms/step - loss: 0.0718 - accuracy: 0.0000e+00 - val_loss: 0.0615 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/2000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0586 - accuracy: 0.0000e+00\n",
            "Epoch 8: val_accuracy did not improve from 0.00000\n",
            "9/9 [==============================] - 2s 233ms/step - loss: 0.0586 - accuracy: 0.0000e+00 - val_loss: 0.0790 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/2000\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0607 - accuracy: 0.0000e+00\n",
            "Epoch 9: val_accuracy did not improve from 0.00000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filepath = '/content/drive/MyDrive/Model_DE/Model.hdf5'\n",
        " \n",
        "checkpoint = [tf.keras.callbacks.ModelCheckpoint(filepath, monitor='accuracy', mode='auto', save_best_only=True, Save_weights_only = False, verbose = 1), \n",
        "              tf.keras.callbacks.EarlyStopping(monitor='accuracy', patience=25, verbose =2)]\n",
        "\n",
        "output_nodes = Y2.shape[1]\n",
        "print(output_nodes)\n",
        "model = tf.keras.Sequential([\n",
        "                             tf.keras.layers.Dense(3524, activation='relu', input_shape=(1762,)),\n",
        "                             tf.keras.layers.Dense(1512, activation='relu'),\n",
        "                             tf.keras.layers.Dense(1512, activation='relu'),\n",
        "                             tf.keras.layers.Dense(output_nodes, activation= 'softmax')])\n",
        "model.compile(optimizer=tf.keras.optimizers.RMSprop(), loss=tf.keras.losses.BinaryCrossentropy(from_logits = False), metrics=['accuracy'])\n",
        "hist = model.fit(X_train, Y2_train, epochs= 2000, callbacks=[checkpoint],validation_data=(X_val, Y2_val), batch_size= 500)\n",
        "model.evaluate(X_test, Y2_test)\n",
        " \n",
        "Y2_train_predict = np.round(model.predict(X_train))\n",
        "Y2_train_l = tf.argmax(Y2_train, axis = 1)\n",
        "Y2_train_predict_l = tf.argmax(Y2_train_predict, axis =1)\n",
        "import sklearn.metrics as skm\n",
        "cm = skm.multilabel_confusion_matrix(Y2_train_l, Y2_train_predict_l)\n",
        "print(cm)\n",
        "print( skm.classification_report(Y2_train_l, Y2_train_predict_l))\n",
        " \n",
        "train_acc = max(hist.history['accuracy'])\n",
        "val_acc = max(hist.history['val_accuracy'])\n",
        "train_loss = min(hist.history['loss'])\n",
        "val_loss = min(hist.history['val_loss'])\n",
        "print('Training Accuracy is')\n",
        "print(train_acc)\n",
        "print('Validation Accuracy is')\n",
        "print(val_acc)\n",
        "print('Training loss is')\n",
        "print(train_loss)\n",
        "print('Validation loss is')\n",
        "print(val_loss)"
      ],
      "metadata": {
        "id": "jTmAQkhsNuQ7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11bee53d-3ee2-48f8-acf6-4d7ec1c1cd2d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "164\n",
            "Epoch 1/2000\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.6491 - accuracy: 0.0000e+00\n",
            "Epoch 1: accuracy improved from -inf to 0.00000, saving model to /content/drive/MyDrive/Model_DE/Model.hdf5\n",
            "2/2 [==============================] - 2s 652ms/step - loss: 0.6491 - accuracy: 0.0000e+00 - val_loss: 0.3198 - val_accuracy: 0.5676\n",
            "Epoch 2/2000\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.3156 - accuracy: 0.5527\n",
            "Epoch 2: accuracy improved from 0.00000 to 0.55271, saving model to /content/drive/MyDrive/Model_DE/Model.hdf5\n",
            "2/2 [==============================] - 1s 499ms/step - loss: 0.3156 - accuracy: 0.5527 - val_loss: 0.3381 - val_accuracy: 0.5676\n",
            "Epoch 3/2000\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.2972 - accuracy: 0.5527\n",
            "Epoch 3: accuracy did not improve from 0.55271\n",
            "2/2 [==============================] - 1s 327ms/step - loss: 0.2972 - accuracy: 0.5527 - val_loss: 0.0916 - val_accuracy: 0.5676\n",
            "Epoch 4/2000\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.0883 - accuracy: 0.5527\n",
            "Epoch 4: accuracy did not improve from 0.55271\n",
            "2/2 [==============================] - 1s 357ms/step - loss: 0.0883 - accuracy: 0.5527 - val_loss: 0.0705 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/2000\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.0680 - accuracy: 0.0000e+00\n",
            "Epoch 5: accuracy did not improve from 0.55271\n",
            "2/2 [==============================] - 1s 343ms/step - loss: 0.0680 - accuracy: 0.0000e+00 - val_loss: 0.0632 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/2000\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.0621 - accuracy: 0.0000e+00\n",
            "Epoch 6: accuracy did not improve from 0.55271\n",
            "2/2 [==============================] - 1s 325ms/step - loss: 0.0621 - accuracy: 0.0000e+00 - val_loss: 0.0629 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/2000\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.0608 - accuracy: 0.0000e+00\n",
            "Epoch 7: accuracy did not improve from 0.55271\n",
            "2/2 [==============================] - 1s 345ms/step - loss: 0.0608 - accuracy: 0.0000e+00 - val_loss: 0.0626 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/2000\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.0612 - accuracy: 0.0000e+00\n",
            "Epoch 8: accuracy did not improve from 0.55271\n",
            "2/2 [==============================] - 1s 344ms/step - loss: 0.0612 - accuracy: 0.0000e+00 - val_loss: 0.0637 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/2000\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.0617 - accuracy: 0.0000e+00\n",
            "Epoch 9: accuracy did not improve from 0.55271\n",
            "2/2 [==============================] - 1s 338ms/step - loss: 0.0617 - accuracy: 0.0000e+00 - val_loss: 0.0634 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/2000\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.0608 - accuracy: 0.0000e+00\n",
            "Epoch 10: accuracy did not improve from 0.55271\n",
            "2/2 [==============================] - 1s 346ms/step - loss: 0.0608 - accuracy: 0.0000e+00 - val_loss: 0.0632 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/2000\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.0605 - accuracy: 0.0000e+00\n",
            "Epoch 11: accuracy did not improve from 0.55271\n",
            "2/2 [==============================] - 1s 345ms/step - loss: 0.0605 - accuracy: 0.0000e+00 - val_loss: 0.0629 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/2000\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.0600 - accuracy: 0.0000e+00\n",
            "Epoch 12: accuracy did not improve from 0.55271\n",
            "2/2 [==============================] - 1s 325ms/step - loss: 0.0600 - accuracy: 0.0000e+00 - val_loss: 0.0641 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/2000\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.0609 - accuracy: 0.0000e+00\n",
            "Epoch 13: accuracy did not improve from 0.55271\n",
            "2/2 [==============================] - 1s 335ms/step - loss: 0.0609 - accuracy: 0.0000e+00 - val_loss: 0.0689 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/2000\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.0654 - accuracy: 0.0000e+00\n",
            "Epoch 14: accuracy did not improve from 0.55271\n",
            "2/2 [==============================] - 1s 347ms/step - loss: 0.0654 - accuracy: 0.0000e+00 - val_loss: 0.0809 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/2000\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.0742 - accuracy: 0.0000e+00\n",
            "Epoch 15: accuracy did not improve from 0.55271\n",
            "2/2 [==============================] - 1s 334ms/step - loss: 0.0742 - accuracy: 0.0000e+00 - val_loss: 0.0636 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/2000\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.0596 - accuracy: 0.0000e+00\n",
            "Epoch 16: accuracy did not improve from 0.55271\n",
            "2/2 [==============================] - 1s 349ms/step - loss: 0.0596 - accuracy: 0.0000e+00 - val_loss: 0.0691 - val_accuracy: 0.0000e+00\n",
            "Epoch 17/2000\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.0639 - accuracy: 0.0000e+00\n",
            "Epoch 17: accuracy did not improve from 0.55271\n",
            "2/2 [==============================] - 1s 339ms/step - loss: 0.0639 - accuracy: 0.0000e+00 - val_loss: 0.0672 - val_accuracy: 0.0000e+00\n",
            "Epoch 18/2000\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.0620 - accuracy: 0.0000e+00\n",
            "Epoch 18: accuracy did not improve from 0.55271\n",
            "2/2 [==============================] - 1s 347ms/step - loss: 0.0620 - accuracy: 0.0000e+00 - val_loss: 0.0662 - val_accuracy: 0.0000e+00\n",
            "Epoch 19/2000\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.0596 - accuracy: 0.0000e+00\n",
            "Epoch 19: accuracy did not improve from 0.55271\n",
            "2/2 [==============================] - 1s 348ms/step - loss: 0.0596 - accuracy: 0.0000e+00 - val_loss: 0.0719 - val_accuracy: 0.0000e+00\n",
            "Epoch 20/2000\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.0639 - accuracy: 0.0000e+00\n",
            "Epoch 20: accuracy did not improve from 0.55271\n",
            "2/2 [==============================] - 1s 342ms/step - loss: 0.0639 - accuracy: 0.0000e+00 - val_loss: 0.0742 - val_accuracy: 0.0000e+00\n",
            "Epoch 21/2000\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.0659 - accuracy: 0.0000e+00\n",
            "Epoch 21: accuracy did not improve from 0.55271\n",
            "2/2 [==============================] - 1s 337ms/step - loss: 0.0659 - accuracy: 0.0000e+00 - val_loss: 0.0647 - val_accuracy: 0.0000e+00\n",
            "Epoch 22/2000\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.0569 - accuracy: 0.0000e+00\n",
            "Epoch 22: accuracy did not improve from 0.55271\n",
            "2/2 [==============================] - 1s 497ms/step - loss: 0.0569 - accuracy: 0.0000e+00 - val_loss: 0.0752 - val_accuracy: 0.0000e+00\n",
            "Epoch 23/2000\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.0669 - accuracy: 0.0000e+00\n",
            "Epoch 23: accuracy did not improve from 0.55271\n",
            "2/2 [==============================] - 1s 401ms/step - loss: 0.0669 - accuracy: 0.0000e+00 - val_loss: 0.0797 - val_accuracy: 0.0000e+00\n",
            "Epoch 24/2000\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.0706 - accuracy: 0.0000e+00\n",
            "Epoch 24: accuracy did not improve from 0.55271\n",
            "2/2 [==============================] - 1s 480ms/step - loss: 0.0706 - accuracy: 0.0000e+00 - val_loss: 0.0691 - val_accuracy: 0.0000e+00\n",
            "Epoch 25/2000\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.0577 - accuracy: 0.0000e+00\n",
            "Epoch 25: accuracy did not improve from 0.55271\n",
            "2/2 [==============================] - 1s 673ms/step - loss: 0.0577 - accuracy: 0.0000e+00 - val_loss: 0.0635 - val_accuracy: 0.0000e+00\n",
            "Epoch 26/2000\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.0538 - accuracy: 0.0000e+00\n",
            "Epoch 26: accuracy did not improve from 0.55271\n",
            "2/2 [==============================] - 2s 719ms/step - loss: 0.0538 - accuracy: 0.0000e+00 - val_loss: 0.0705 - val_accuracy: 0.0000e+00\n",
            "Epoch 27/2000\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.0582 - accuracy: 0.0000e+00\n",
            "Epoch 27: accuracy did not improve from 0.55271\n",
            "2/2 [==============================] - 1s 484ms/step - loss: 0.0582 - accuracy: 0.0000e+00 - val_loss: 0.0642 - val_accuracy: 0.0000e+00\n",
            "Epoch 27: early stopping\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 0.0632 - accuracy: 0.0000e+00\n",
            "[[[297.   0.]\n",
            "  [367.   0.]]\n",
            "\n",
            " [[367.   0.]\n",
            "  [297.   0.]]\n",
            "\n",
            " [[  0. 664.]\n",
            "  [  0.   0.]]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00     367.0\n",
            "           1       0.00      0.00      0.00     297.0\n",
            "         109       0.00      0.00      0.00       0.0\n",
            "\n",
            "    accuracy                           0.00     664.0\n",
            "   macro avg       0.00      0.00      0.00     664.0\n",
            "weighted avg       0.00      0.00      0.00     664.0\n",
            "\n",
            "Training Accuracy is\n",
            "0.5527108311653137\n",
            "Validation Accuracy is\n",
            "0.5675675868988037\n",
            "Training loss is\n",
            "0.05384229123592377\n",
            "Validation loss is\n",
            "0.06263796985149384\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t1 = model.predict(X_train[0:5,:])\n",
        "print(t1)\n",
        " \n",
        "t = np.round(model.predict(X_train))\n",
        "print(t)\n",
        " \n",
        "Y_prediction = enc.inverse_transform(t)\n",
        "print(Y1.head(),Y_prediction, Y_prediction.shape)\n"
      ],
      "metadata": {
        "id": "5hHT-inrRYAY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ac0eb6b-0986-4ee7-ce0c-f31cb0427909"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1.71530455e-01 8.16830218e-01 6.65873110e-01 3.60201508e-01\n",
            "  1.99705362e-04 2.29805708e-04 6.58282876e-01 3.73521060e-01\n",
            "  2.51263380e-04 2.94816494e-03 1.98728012e-05 8.19228371e-05\n",
            "  3.87079358e-01 4.11924448e-05 2.22253799e-03 4.13147867e-01\n",
            "  2.75138021e-03 2.40655124e-01 8.58038664e-04 1.06510520e-03\n",
            "  6.77317381e-04 7.55854368e-01 2.60028243e-03 2.05155629e-05\n",
            "  2.05650061e-01 1.74760818e-04 9.11428579e-05 9.99983191e-01\n",
            "  7.51295805e-01 2.40557075e-01 8.49283970e-05 2.69323587e-04\n",
            "  1.92046165e-04 1.62856122e-05 1.26387904e-05]\n",
            " [4.54753081e-06 9.99998808e-01 2.39379663e-08 9.99999285e-01\n",
            "  1.53970058e-21 4.55224325e-17 9.99996603e-01 1.51708662e-06\n",
            "  5.24412413e-15 5.02116237e-10 1.25044635e-20 1.46101262e-18\n",
            "  9.99990106e-01 7.79245744e-18 7.07244983e-12 3.66711191e-07\n",
            "  1.82847085e-10 8.12716561e-09 7.39361304e-14 1.21551515e-14\n",
            "  1.19079825e-18 2.98875129e-05 3.23215318e-05 9.99941826e-01\n",
            "  7.37296613e-11 6.56344163e-12 6.15678307e-15 1.00000000e+00\n",
            "  1.00000000e+00 1.53888472e-13 3.61246241e-11 9.01885530e-16\n",
            "  1.14556944e-16 1.52727656e-20 9.81258705e-20]\n",
            " [3.42680305e-01 6.34343863e-01 1.69472158e-01 8.15307021e-01\n",
            "  5.90914424e-05 4.11806434e-01 6.34289920e-01 1.38047338e-03\n",
            "  2.29153961e-01 3.48985195e-04 5.19861885e-07 1.93520691e-06\n",
            "  6.69557273e-01 8.23437313e-06 7.68065453e-04 2.12317705e-03\n",
            "  2.36512691e-01 2.21937895e-04 3.01985765e-05 1.70704807e-05\n",
            "  3.72480190e-06 9.98224854e-01 1.10560656e-03 1.57884938e-06\n",
            "  3.36557627e-04 3.61995008e-05 5.05076196e-06 9.99999166e-01\n",
            "  9.98685718e-01 8.48260825e-05 2.03863328e-05 1.02364880e-04\n",
            "  3.85187559e-06 6.84045801e-07 5.12431711e-07]\n",
            " [9.99811649e-01 2.00182199e-04 3.06243419e-06 9.99999523e-01\n",
            "  7.72371750e-12 2.09958231e-13 9.99995887e-01 2.67918745e-06\n",
            "  1.61381835e-12 3.98116609e-11 4.45538043e-14 9.99906540e-01\n",
            "  3.17183731e-06 7.03605565e-06 1.64753365e-05 7.77883251e-05\n",
            "  1.09948205e-11 8.25644165e-05 1.07556446e-11 7.03483203e-16\n",
            "  9.34754390e-14 9.99879777e-01 1.71687007e-05 2.63562663e-13\n",
            "  2.86006916e-08 4.95633753e-13 1.48591805e-14 1.00000000e+00\n",
            "  6.21746585e-05 9.99919951e-01 3.70467573e-10 7.63509589e-10\n",
            "  3.10840307e-12 3.59809161e-14 3.80825335e-13]\n",
            " [4.46656406e-01 5.22483826e-01 2.29489803e-03 9.96411085e-01\n",
            "  3.36229801e-04 7.41027834e-05 9.97405589e-01 4.51117754e-04\n",
            "  7.81896524e-05 2.69114971e-04 3.22461756e-06 6.67199565e-05\n",
            "  4.14112210e-03 9.37834848e-05 2.59572268e-03 4.11111951e-01\n",
            "  5.10012984e-01 6.08175993e-04 5.00808128e-05 9.53335621e-06\n",
            "  1.92915468e-05 9.94918644e-01 1.12861395e-03 7.12975680e-06\n",
            "  5.47826290e-04 5.88703597e-06 6.31380462e-05 9.99994755e-01\n",
            "  3.76868248e-01 2.41607428e-04 2.23487616e-04 5.30743122e-01\n",
            "  1.34468079e-04 3.14634644e-06 1.00303287e-05]]\n",
            "[[0. 1. 1. ... 0. 0. 0.]\n",
            " [0. 1. 0. ... 0. 0. 0.]\n",
            " [0. 1. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 1. 1. ... 0. 0. 0.]\n",
            " [0. 1. 0. ... 0. 0. 0.]\n",
            " [0. 1. 0. ... 0. 0. 0.]]\n",
            "  METHANOL ACETONITRILE WATER                          BUFFER OTHER    PHASE  \\\n",
            "0       No          Yes    No  Potassium dihydrogen phosphate    No  Reverse   \n",
            "1      Yes           No    No                Phosphate buffer    No  Reverse   \n",
            "2       No          Yes    No  Potassium dihydrogen phosphate    No  Reverse   \n",
            "3      Yes           No    No  Potassium dihydrogen phosphate    No  Reverse   \n",
            "4       No          Yes    No  Potassium dihydrogen phosphate    No  Reverse   \n",
            "\n",
            "  COLUMN  \n",
            "0    C-8  \n",
            "1   C-18  \n",
            "2   C-18  \n",
            "3    C-8  \n",
            "4   C-18   [['Yes' 'No' 'No' None 'No' 'Reverse' 'C-18']\n",
            " ['Yes' 'Yes' 'No' 'No' 'Potassium dihydrogen phosphate and TEA'\n",
            "  'Reverse' 'C-18']\n",
            " ['Yes' 'Yes' 'No' 'No' 'No' 'Reverse' 'C-18']\n",
            " ['No' 'Yes' 'No' 'Disodium hydrogen phosphate' 'No' 'Reverse' 'C-8']\n",
            " ['Yes' 'Yes' 'No' 'Sodium acetate' 'No' 'Reverse' 'InertsilODS-3V']\n",
            " ['Yes' 'No' 'No' None 'No' 'Reverse' 'C-18']\n",
            " ['No' 'Yes' 'No' 'Sodium dihydrogen phosphate' 'No' 'Reverse' 'C-18']\n",
            " ['Yes' 'Yes' 'No' 'Potassium dihydrogen phosphate' 'No' 'Reverse' 'C-18']\n",
            " ['No' 'Yes' 'No' 'Phosphate buffer' 'No' 'Reverse' 'C-18']\n",
            " ['Yes' 'No' 'No' None 'NaOH' 'Reverse' 'C-18']\n",
            " ['Yes' 'Yes' 'No' 'No' None 'Reverse' 'C-18']\n",
            " ['Yes' 'No' 'No' 'No' None 'Reverse' 'C-18']\n",
            " ['Yes' 'No' 'No' None 'No' 'Reverse' 'C-18']\n",
            " ['Yes' 'No' 'No' 'Potassium dihydrogen phosphate' 'No' 'Reverse' 'C-18']\n",
            " ['No' 'Yes' 'Yes' 'No' 'Ortho Phosphoric acid' 'Reverse' 'C-18']\n",
            " ['Yes' 'No' 'Yes' 'No' 'Ortho Phosphoric acid' 'Reverse' 'C-18']\n",
            " ['Yes' 'Yes' 'No' 'No' 'No' 'Reverse' 'C-18']\n",
            " ['Yes' 'No' 'Yes' 'No' 'Acetic acid' 'Reverse' 'C-18']\n",
            " ['No' 'Yes' 'No' None None 'Reverse' 'C-18']\n",
            " ['No' 'Yes' 'No' 'Potassium dihydrogen phosphate'\n",
            "  'Ortho Phosphoric acid' 'Reverse' 'C-18']\n",
            " ['Yes' 'No' 'Yes' 'No' 'Acetic acid' 'Reverse' 'C-18']\n",
            " ['Yes' 'No' 'No' None 'No' 'Reverse' 'C-18']\n",
            " ['Yes' 'No' 'No' None 'NaOH' 'Reverse' 'C-18']\n",
            " ['No' 'Yes' 'No' 'Phosphate buffer' 'No' 'Reverse' 'C-18']\n",
            " ['Yes' 'No' 'No' None 'No' 'Reverse' 'C-18']\n",
            " ['Yes' 'Yes' 'No' 'Potassium dihydrogen phosphate' 'No' 'Reverse' 'C-18']\n",
            " ['Yes' 'No' 'No' None 'No' 'Reverse' 'C-18']\n",
            " ['No' 'Yes' 'No' 'Sodium dihydrogen phosphate' 'No' 'Reverse' 'C-18']\n",
            " ['Yes' 'No' 'No' 'No' None 'Reverse' 'C-18']\n",
            " ['Yes' 'No' 'No' 'Potassium dihydrogen phosphate' 'No' 'Reverse' 'C-18']\n",
            " ['Yes' 'Yes' 'Yes' 'No' 'No' 'Reverse' 'C-18']\n",
            " ['No' 'Yes' 'No' 'Phosphate buffer' 'No' 'Reverse' 'C-18']\n",
            " ['No' 'Yes' 'No' 'Phosphate buffer' 'No' 'Reverse' 'C-18']\n",
            " ['Yes' 'No' 'Yes' 'No' 'No' 'Reverse' 'C-18']\n",
            " ['Yes' 'Yes' 'No' 'No' None 'Reverse' 'C-18']\n",
            " ['Yes' 'Yes' 'No' None None 'Reverse' 'PhenomenexLuna']\n",
            " ['Yes' 'Yes' 'No' 'Ortho Phosphoric acid' 'No' 'Reverse' 'C-8']\n",
            " ['Yes' 'Yes' 'No' None None 'Reverse' 'PhenomenexLuna']\n",
            " ['No' 'Yes' 'No' None None 'Reverse' 'C-18']\n",
            " ['Yes' 'Yes' 'No' 'No' None 'Reverse' 'InertsilODS-3']\n",
            " ['No' 'Yes' '     Yes' 'Potassium dihydrogen phosphate' 'No' 'Reverse'\n",
            "  'C-18']\n",
            " ['Yes' 'Yes' 'No' 'No' 'Ortho Phosphoric acid' 'Reverse' 'C-18']\n",
            " ['No' 'Yes' 'No' None None 'Reverse' 'C-18']\n",
            " ['No' 'Yes' 'Yes' 'No' 'No' 'Reverse' 'C-18']\n",
            " ['Yes' 'Yes' 'No' 'No' None 'Reverse' 'InertsilODS-3']\n",
            " ['No' 'Yes' 'No' None None 'Reverse' 'C-18']\n",
            " ['Yes' 'Yes' 'No' None 'No' 'Reverse' 'C-18']\n",
            " ['Yes' 'No' 'No' 'No' None 'Reverse' 'C-18']\n",
            " ['Yes' 'Yes' 'No' 'Potassium dihydrogen phosphate' 'No' 'Reverse' 'C-18']\n",
            " ['No' 'Yes' 'No' None None 'Reverse' 'C-18']\n",
            " ['No' 'Yes' 'Yes' 'No' 'Trifluroacetic acid' 'Reverse' 'C-18']\n",
            " ['Yes' 'Yes' 'No' 'No' 'No' 'Reverse' 'C-18']\n",
            " ['Yes' 'No' 'No' 'No' None 'Reverse' 'C-18']\n",
            " ['No' 'Yes' 'No' 'Potassium dihydrogen phosphate' 'No' 'Reverse' 'C-18']\n",
            " ['Yes' 'Yes' 'No' 'Phosphate buffer' 'No' 'Reverse' 'C-18']\n",
            " ['Yes' 'Yes' 'No' 'No' None 'Reverse' 'C-18']\n",
            " ['Yes' 'No' 'No' 'Potassium dihydrogen phosphate' 'No' 'Reverse' 'C-8']\n",
            " ['Yes' 'Yes' 'No' 'Phosphate buffer' 'No' 'Reverse' 'C-18']\n",
            " ['No' 'Yes' 'No' 'Potassium dihydrogen phosphate'\n",
            "  'Ortho Phosphoric acid' 'Reverse' 'C-18']\n",
            " ['No' 'Yes' 'No' 'Potassium dihydrogen phosphate' 'No' 'Reverse' 'C-18']\n",
            " ['Yes' 'No' 'No' 'Sodium acetate' 'No' 'Reverse' 'C-18']\n",
            " ['Yes' 'Yes' 'No' None 'No' 'Reverse' 'C-18']\n",
            " ['Yes' 'Yes' 'No' 'No' 'No' 'Reverse' 'C-18']\n",
            " ['Yes' 'Yes' 'No' 'No' 'No' 'Reverse' 'C-18']\n",
            " ['No' 'Yes' 'No' 'Phosphate buffer' 'No' 'Reverse' 'C-18']\n",
            " ['No' 'Yes' 'No' None None 'Reverse' 'C-18']\n",
            " ['Yes' 'No' 'No' 'Potassium dihydrogen phosphate' 'No' 'Reverse' 'C-18']\n",
            " ['Yes' 'No' 'No' 'Ammonium acetate ' 'No' 'Reverse' 'C-18']\n",
            " ['Yes' 'Yes' 'No' 'Sodium acetate' 'No' 'Reverse' 'InertsilODS-3V']\n",
            " ['Yes' 'Yes' 'No' 'No' None 'Reverse' 'C-18']] (70, 7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X.to_csv('Drug_1.csv')"
      ],
      "metadata": {
        "id": "wn49FyCQWw6R"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}