{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Swayamprakashpatel/HPLC/blob/main/HPLC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "hdOKQlX8nYHN"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pandas_datareader as web\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from google.colab import files\n",
        "import time as tm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/Data.csv')\n",
        "df = pd.DataFrame(df)\n",
        "df = df.iloc[:,:]\n",
        "\n",
        "X1 = df.iloc[:, 11:13]\n",
        "X1 = X1.div(20).round(2) \n",
        "\n",
        "X2 = df.iloc[:, 13:]\n",
        "X = [X1,X2]\n",
        "X = pd.concat(X, axis=1)\n",
        "\n",
        "Y_Cat = df.iloc[:, 4:7]\n",
        "Y_Num = df.iloc[:,7:11]\n",
        "X.head(),Y_Cat.head(), Y_Num.head()\n",
        "print(X.shape, Y_Cat.shape, Y_Num.shape)"
      ],
      "metadata": {
        "id": "pWFUSWyuSmAe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73fa30b6-68db-45be-c682-3e064156e901"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1108, 1764) (1108, 3) (1108, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "xUYrz-fYpHKK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9f0a0a1-3b35-4828-face-1a086ef8b94f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1. 0. 0. 1. 1. 0.]\n",
            " [0. 1. 1. 0. 1. 0.]\n",
            " [1. 0. 0. 1. 1. 0.]\n",
            " ...\n",
            " [1. 0. 1. 0. 0. 1.]\n",
            " [1. 0. 0. 1. 0. 1.]\n",
            " [0. 1. 1. 0. 1. 0.]] (1108, 6)\n",
            "(1108, 6)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "enc = OneHotEncoder(handle_unknown='ignore')\n",
        "\n",
        "enc.fit(Y_Cat)\n",
        "OneHotEncoder(handle_unknown='ignore')\n",
        "enc.categories_\n",
        "\n",
        "Y_Cat_OH = enc.transform(Y_Cat).toarray() #Categorical Data\n",
        "print(Y_Cat_OH,Y_Cat_OH.shape)\n",
        "\n",
        "print(Y_Cat_OH.shape)\n",
        "\n",
        "Y2 = Y_Cat_OH"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(Y2,Y2.shape[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7aDLRxuxu6NS",
        "outputId": "b363c194-bd10-44af-c2ed-c359fbb34eed"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1. 0. 0. 1. 1. 0.]\n",
            " [0. 1. 1. 0. 1. 0.]\n",
            " [1. 0. 0. 1. 1. 0.]\n",
            " ...\n",
            " [1. 0. 1. 0. 0. 1.]\n",
            " [1. 0. 0. 1. 0. 1.]\n",
            " [0. 1. 1. 0. 1. 0.]] 6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "_c6AzknaMkOr"
      },
      "outputs": [],
      "source": [
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_val_and_test, Y2_train, Y2_val_and_test = train_test_split(X, Y2, test_size=0.01,random_state = 42 )\n",
        "X_val, X_test, Y2_val, Y2_test = train_test_split(X_val_and_test, Y2_val_and_test, test_size=0.5, random_state= 42)\n",
        "\n",
        "X_train = np.asarray(X_train).astype(np.int64)\n",
        "X_val = np.asarray(X_val).astype(np.int64)\n",
        "X_test = np.asarray(X_test).astype(np.int64)\n",
        "Y2_train = np.asarray(Y2_train).astype(np.int64)\n",
        "Y2_val = np.asarray(Y2_val).astype(np.int64)\n",
        "Y2_test = np.asarray(Y2_test).astype(np.int64)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.shape)"
      ],
      "metadata": {
        "id": "D_M243pwVqaj",
        "outputId": "aba1bfb4-bc4a-439c-de7d-df33c07f94eb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1096, 1764)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "bl6TPQWc79WI"
      },
      "outputs": [],
      "source": [
        "import datetime\n",
        "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jTmAQkhsNuQ7",
        "outputId": "13391e92-dd9e-4416-c13d-b0891bb698ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6\n",
            "Epoch 1/2000\n",
            "7/8 [=========================>....] - ETA: 0s - loss: nan - accuracy: 0.3800\n",
            "Epoch 1: accuracy improved from -inf to 0.38686, saving model to /content/drive/MyDrive/Model_DE/Model.hdf5\n",
            "8/8 [==============================] - 1s 128ms/step - loss: nan - accuracy: 0.3869 - val_loss: nan - val_accuracy: 0.5000\n",
            "Epoch 2/2000\n",
            "7/8 [=========================>....] - ETA: 0s - loss: nan - accuracy: 0.5524\n",
            "Epoch 2: accuracy improved from 0.38686 to 0.55474, saving model to /content/drive/MyDrive/Model_DE/Model.hdf5\n",
            "8/8 [==============================] - 1s 100ms/step - loss: nan - accuracy: 0.5547 - val_loss: nan - val_accuracy: 0.5000\n",
            "Epoch 3/2000\n",
            "7/8 [=========================>....] - ETA: 0s - loss: nan - accuracy: 0.5590\n",
            "Epoch 3: accuracy did not improve from 0.55474\n",
            "8/8 [==============================] - 1s 84ms/step - loss: nan - accuracy: 0.5547 - val_loss: nan - val_accuracy: 0.5000\n",
            "Epoch 4/2000\n",
            "7/8 [=========================>....] - ETA: 0s - loss: nan - accuracy: 0.5505\n",
            "Epoch 4: accuracy did not improve from 0.55474\n",
            "8/8 [==============================] - 1s 81ms/step - loss: nan - accuracy: 0.5547 - val_loss: nan - val_accuracy: 0.5000\n",
            "Epoch 5/2000\n",
            "8/8 [==============================] - ETA: 0s - loss: nan - accuracy: 0.5547\n",
            "Epoch 5: accuracy did not improve from 0.55474\n",
            "8/8 [==============================] - 1s 86ms/step - loss: nan - accuracy: 0.5547 - val_loss: nan - val_accuracy: 0.5000\n",
            "Epoch 6/2000\n",
            "7/8 [=========================>....] - ETA: 0s - loss: nan - accuracy: 0.5505\n",
            "Epoch 6: accuracy did not improve from 0.55474\n",
            "8/8 [==============================] - 1s 81ms/step - loss: nan - accuracy: 0.5547 - val_loss: nan - val_accuracy: 0.5000\n",
            "Epoch 7/2000\n",
            "7/8 [=========================>....] - ETA: 0s - loss: nan - accuracy: 0.5562\n",
            "Epoch 7: accuracy did not improve from 0.55474\n",
            "8/8 [==============================] - 1s 79ms/step - loss: nan - accuracy: 0.5547 - val_loss: nan - val_accuracy: 0.5000\n",
            "Epoch 8/2000\n",
            "7/8 [=========================>....] - ETA: 0s - loss: nan - accuracy: 0.5552\n",
            "Epoch 8: accuracy did not improve from 0.55474\n",
            "8/8 [==============================] - 1s 81ms/step - loss: nan - accuracy: 0.5547 - val_loss: nan - val_accuracy: 0.5000\n",
            "Epoch 9/2000\n",
            "7/8 [=========================>....] - ETA: 0s - loss: nan - accuracy: 0.5619\n",
            "Epoch 9: accuracy did not improve from 0.55474\n",
            "8/8 [==============================] - 1s 81ms/step - loss: nan - accuracy: 0.5547 - val_loss: nan - val_accuracy: 0.5000\n",
            "Epoch 10/2000\n",
            "7/8 [=========================>....] - ETA: 0s - loss: nan - accuracy: 0.5571\n",
            "Epoch 10: accuracy did not improve from 0.55474\n",
            "8/8 [==============================] - 1s 81ms/step - loss: nan - accuracy: 0.5547 - val_loss: nan - val_accuracy: 0.5000\n",
            "Epoch 11/2000\n",
            "7/8 [=========================>....] - ETA: 0s - loss: nan - accuracy: 0.5581\n",
            "Epoch 11: accuracy did not improve from 0.55474\n",
            "8/8 [==============================] - 1s 81ms/step - loss: nan - accuracy: 0.5547 - val_loss: nan - val_accuracy: 0.5000\n",
            "Epoch 12/2000\n",
            "8/8 [==============================] - ETA: 0s - loss: nan - accuracy: 0.5547\n",
            "Epoch 12: accuracy did not improve from 0.55474\n",
            "8/8 [==============================] - 1s 81ms/step - loss: nan - accuracy: 0.5547 - val_loss: nan - val_accuracy: 0.5000\n",
            "Epoch 13/2000\n",
            "7/8 [=========================>....] - ETA: 0s - loss: nan - accuracy: 0.5571\n",
            "Epoch 13: accuracy did not improve from 0.55474\n",
            "8/8 [==============================] - 1s 81ms/step - loss: nan - accuracy: 0.5547 - val_loss: nan - val_accuracy: 0.5000\n",
            "Epoch 14/2000\n",
            "7/8 [=========================>....] - ETA: 0s - loss: nan - accuracy: 0.5552\n",
            "Epoch 14: accuracy did not improve from 0.55474\n",
            "8/8 [==============================] - 1s 81ms/step - loss: nan - accuracy: 0.5547 - val_loss: nan - val_accuracy: 0.5000\n",
            "Epoch 15/2000\n",
            "7/8 [=========================>....] - ETA: 0s - loss: nan - accuracy: 0.5562\n",
            "Epoch 15: accuracy did not improve from 0.55474\n",
            "8/8 [==============================] - 1s 79ms/step - loss: nan - accuracy: 0.5547 - val_loss: nan - val_accuracy: 0.5000\n",
            "Epoch 16/2000\n",
            "7/8 [=========================>....] - ETA: 0s - loss: nan - accuracy: 0.5562\n",
            "Epoch 16: accuracy did not improve from 0.55474\n",
            "8/8 [==============================] - 1s 79ms/step - loss: nan - accuracy: 0.5547 - val_loss: nan - val_accuracy: 0.5000\n",
            "Epoch 17/2000\n",
            "7/8 [=========================>....] - ETA: 0s - loss: nan - accuracy: 0.5543\n",
            "Epoch 17: accuracy did not improve from 0.55474\n",
            "8/8 [==============================] - 1s 81ms/step - loss: nan - accuracy: 0.5547 - val_loss: nan - val_accuracy: 0.5000\n",
            "Epoch 18/2000\n",
            "7/8 [=========================>....] - ETA: 0s - loss: nan - accuracy: 0.5524\n",
            "Epoch 18: accuracy did not improve from 0.55474\n",
            "8/8 [==============================] - 1s 76ms/step - loss: nan - accuracy: 0.5547 - val_loss: nan - val_accuracy: 0.5000\n",
            "Epoch 19/2000\n",
            "7/8 [=========================>....] - ETA: 0s - loss: nan - accuracy: 0.5524\n",
            "Epoch 19: accuracy did not improve from 0.55474\n",
            "8/8 [==============================] - 1s 81ms/step - loss: nan - accuracy: 0.5547 - val_loss: nan - val_accuracy: 0.5000\n",
            "Epoch 20/2000\n",
            "7/8 [=========================>....] - ETA: 0s - loss: nan - accuracy: 0.5590\n",
            "Epoch 20: accuracy did not improve from 0.55474\n",
            "8/8 [==============================] - 1s 82ms/step - loss: nan - accuracy: 0.5547 - val_loss: nan - val_accuracy: 0.5000\n",
            "Epoch 21/2000\n",
            "7/8 [=========================>....] - ETA: 0s - loss: nan - accuracy: 0.5533\n",
            "Epoch 21: accuracy did not improve from 0.55474\n",
            "8/8 [==============================] - 1s 83ms/step - loss: nan - accuracy: 0.5547 - val_loss: nan - val_accuracy: 0.5000\n",
            "Epoch 22/2000\n",
            "7/8 [=========================>....] - ETA: 0s - loss: nan - accuracy: 0.5581\n",
            "Epoch 22: accuracy did not improve from 0.55474\n",
            "8/8 [==============================] - 1s 80ms/step - loss: nan - accuracy: 0.5547 - val_loss: nan - val_accuracy: 0.5000\n",
            "Epoch 23/2000\n",
            "8/8 [==============================] - ETA: 0s - loss: nan - accuracy: 0.5547\n",
            "Epoch 23: accuracy did not improve from 0.55474\n",
            "8/8 [==============================] - 1s 82ms/step - loss: nan - accuracy: 0.5547 - val_loss: nan - val_accuracy: 0.5000\n",
            "Epoch 24/2000\n",
            "7/8 [=========================>....] - ETA: 0s - loss: nan - accuracy: 0.5543\n",
            "Epoch 24: accuracy did not improve from 0.55474\n",
            "8/8 [==============================] - 1s 77ms/step - loss: nan - accuracy: 0.5547 - val_loss: nan - val_accuracy: 0.5000\n",
            "Epoch 25/2000\n",
            "7/8 [=========================>....] - ETA: 0s - loss: nan - accuracy: 0.5524\n",
            "Epoch 25: accuracy did not improve from 0.55474\n",
            "8/8 [==============================] - 1s 81ms/step - loss: nan - accuracy: 0.5547 - val_loss: nan - val_accuracy: 0.5000\n",
            "Epoch 26/2000\n",
            "7/8 [=========================>....] - ETA: 0s - loss: nan - accuracy: 0.5552\n",
            "Epoch 26: accuracy did not improve from 0.55474\n",
            "8/8 [==============================] - 1s 81ms/step - loss: nan - accuracy: 0.5547 - val_loss: nan - val_accuracy: 0.5000\n",
            "Epoch 27/2000\n",
            "7/8 [=========================>....] - ETA: 0s - loss: nan - accuracy: 0.5581\n",
            "Epoch 27: accuracy did not improve from 0.55474\n",
            "8/8 [==============================] - 1s 79ms/step - loss: nan - accuracy: 0.5547 - val_loss: nan - val_accuracy: 0.5000\n",
            "Epoch 28/2000\n",
            "7/8 [=========================>....] - ETA: 0s - loss: nan - accuracy: 0.5543\n",
            "Epoch 28: accuracy did not improve from 0.55474\n",
            "8/8 [==============================] - 1s 82ms/step - loss: nan - accuracy: 0.5547 - val_loss: nan - val_accuracy: 0.5000\n",
            "Epoch 29/2000\n",
            "7/8 [=========================>....] - ETA: 0s - loss: nan - accuracy: 0.5533\n",
            "Epoch 29: accuracy did not improve from 0.55474\n",
            "8/8 [==============================] - 1s 80ms/step - loss: nan - accuracy: 0.5547 - val_loss: nan - val_accuracy: 0.5000\n",
            "Epoch 30/2000\n",
            "7/8 [=========================>....] - ETA: 0s - loss: nan - accuracy: 0.5533\n",
            "Epoch 30: accuracy did not improve from 0.55474\n",
            "8/8 [==============================] - 1s 81ms/step - loss: nan - accuracy: 0.5547 - val_loss: nan - val_accuracy: 0.5000\n",
            "Epoch 31/2000\n",
            "7/8 [=========================>....] - ETA: 0s - loss: nan - accuracy: 0.5514\n",
            "Epoch 31: accuracy did not improve from 0.55474\n",
            "8/8 [==============================] - 1s 81ms/step - loss: nan - accuracy: 0.5547 - val_loss: nan - val_accuracy: 0.5000\n",
            "Epoch 32/2000\n",
            "7/8 [=========================>....] - ETA: 0s - loss: nan - accuracy: 0.5562\n",
            "Epoch 32: accuracy did not improve from 0.55474\n",
            "8/8 [==============================] - 1s 79ms/step - loss: nan - accuracy: 0.5547 - val_loss: nan - val_accuracy: 0.5000\n",
            "Epoch 33/2000\n",
            "7/8 [=========================>....] - ETA: 0s - loss: nan - accuracy: 0.5552\n",
            "Epoch 33: accuracy did not improve from 0.55474\n",
            "8/8 [==============================] - 1s 80ms/step - loss: nan - accuracy: 0.5547 - val_loss: nan - val_accuracy: 0.5000\n",
            "Epoch 34/2000\n",
            "7/8 [=========================>....] - ETA: 0s - loss: nan - accuracy: 0.5495\n",
            "Epoch 34: accuracy did not improve from 0.55474\n",
            "8/8 [==============================] - 1s 82ms/step - loss: nan - accuracy: 0.5547 - val_loss: nan - val_accuracy: 0.5000\n",
            "Epoch 35/2000\n",
            "7/8 [=========================>....] - ETA: 0s - loss: nan - accuracy: 0.5571\n",
            "Epoch 35: accuracy did not improve from 0.55474\n",
            "8/8 [==============================] - 1s 78ms/step - loss: nan - accuracy: 0.5547 - val_loss: nan - val_accuracy: 0.5000\n",
            "Epoch 36/2000\n",
            "7/8 [=========================>....] - ETA: 0s - loss: nan - accuracy: 0.5610\n",
            "Epoch 36: accuracy did not improve from 0.55474\n",
            "8/8 [==============================] - 1s 82ms/step - loss: nan - accuracy: 0.5547 - val_loss: nan - val_accuracy: 0.5000\n",
            "Epoch 37/2000\n",
            "7/8 [=========================>....] - ETA: 0s - loss: nan - accuracy: 0.5610\n",
            "Epoch 37: accuracy did not improve from 0.55474\n",
            "8/8 [==============================] - 1s 80ms/step - loss: nan - accuracy: 0.5547 - val_loss: nan - val_accuracy: 0.5000\n",
            "Epoch 38/2000\n",
            "7/8 [=========================>....] - ETA: 0s - loss: nan - accuracy: 0.5543\n",
            "Epoch 38: accuracy did not improve from 0.55474\n",
            "8/8 [==============================] - 1s 83ms/step - loss: nan - accuracy: 0.5547 - val_loss: nan - val_accuracy: 0.5000\n",
            "Epoch 39/2000\n",
            "7/8 [=========================>....] - ETA: 0s - loss: nan - accuracy: 0.5571\n",
            "Epoch 39: accuracy did not improve from 0.55474\n",
            "8/8 [==============================] - 1s 81ms/step - loss: nan - accuracy: 0.5547 - val_loss: nan - val_accuracy: 0.5000\n",
            "Epoch 40/2000\n",
            "7/8 [=========================>....] - ETA: 0s - loss: nan - accuracy: 0.5600\n",
            "Epoch 40: accuracy did not improve from 0.55474\n",
            "8/8 [==============================] - 1s 79ms/step - loss: nan - accuracy: 0.5547 - val_loss: nan - val_accuracy: 0.5000\n",
            "Epoch 41/2000\n",
            "7/8 [=========================>....] - ETA: 0s - loss: nan - accuracy: 0.5543\n",
            "Epoch 41: accuracy did not improve from 0.55474\n",
            "8/8 [==============================] - 1s 81ms/step - loss: nan - accuracy: 0.5547 - val_loss: nan - val_accuracy: 0.5000\n",
            "Epoch 42/2000\n",
            "7/8 [=========================>....] - ETA: 0s - loss: nan - accuracy: 0.5581\n",
            "Epoch 42: accuracy did not improve from 0.55474\n",
            "8/8 [==============================] - 1s 83ms/step - loss: nan - accuracy: 0.5547 - val_loss: nan - val_accuracy: 0.5000\n",
            "Epoch 43/2000\n",
            "7/8 [=========================>....] - ETA: 0s - loss: nan - accuracy: 0.5524\n",
            "Epoch 43: accuracy did not improve from 0.55474\n",
            "8/8 [==============================] - 1s 81ms/step - loss: nan - accuracy: 0.5547 - val_loss: nan - val_accuracy: 0.5000\n",
            "Epoch 44/2000\n",
            "7/8 [=========================>....] - ETA: 0s - loss: nan - accuracy: 0.5581\n",
            "Epoch 44: accuracy did not improve from 0.55474\n",
            "8/8 [==============================] - 1s 82ms/step - loss: nan - accuracy: 0.5547 - val_loss: nan - val_accuracy: 0.5000\n",
            "Epoch 45/2000\n",
            "7/8 [=========================>....] - ETA: 0s - loss: nan - accuracy: 0.5562\n",
            "Epoch 45: accuracy did not improve from 0.55474\n",
            "8/8 [==============================] - 1s 83ms/step - loss: nan - accuracy: 0.5547 - val_loss: nan - val_accuracy: 0.5000\n",
            "Epoch 46/2000\n",
            "7/8 [=========================>....] - ETA: 0s - loss: nan - accuracy: 0.5610\n",
            "Epoch 46: accuracy did not improve from 0.55474\n",
            "8/8 [==============================] - 1s 79ms/step - loss: nan - accuracy: 0.5547 - val_loss: nan - val_accuracy: 0.5000\n",
            "Epoch 47/2000\n",
            "7/8 [=========================>....] - ETA: 0s - loss: nan - accuracy: 0.5533\n",
            "Epoch 47: accuracy did not improve from 0.55474\n",
            "8/8 [==============================] - 1s 81ms/step - loss: nan - accuracy: 0.5547 - val_loss: nan - val_accuracy: 0.5000\n",
            "Epoch 48/2000\n",
            "7/8 [=========================>....] - ETA: 0s - loss: nan - accuracy: 0.5533\n",
            "Epoch 48: accuracy did not improve from 0.55474\n",
            "8/8 [==============================] - 1s 79ms/step - loss: nan - accuracy: 0.5547 - val_loss: nan - val_accuracy: 0.5000\n",
            "Epoch 49/2000\n",
            "7/8 [=========================>....] - ETA: 0s - loss: nan - accuracy: 0.5610\n",
            "Epoch 49: accuracy did not improve from 0.55474\n",
            "8/8 [==============================] - 1s 80ms/step - loss: nan - accuracy: 0.5547 - val_loss: nan - val_accuracy: 0.5000\n",
            "Epoch 50/2000\n",
            "7/8 [=========================>....] - ETA: 0s - loss: nan - accuracy: 0.5543\n",
            "Epoch 50: accuracy did not improve from 0.55474\n",
            "8/8 [==============================] - 1s 80ms/step - loss: nan - accuracy: 0.5547 - val_loss: nan - val_accuracy: 0.5000\n",
            "Epoch 51/2000\n",
            "7/8 [=========================>....] - ETA: 0s - loss: nan - accuracy: 0.5543\n",
            "Epoch 51: accuracy did not improve from 0.55474\n",
            "8/8 [==============================] - 1s 80ms/step - loss: nan - accuracy: 0.5547 - val_loss: nan - val_accuracy: 0.5000\n",
            "Epoch 52/2000\n",
            "7/8 [=========================>....] - ETA: 0s - loss: nan - accuracy: 0.5543\n",
            "Epoch 52: accuracy did not improve from 0.55474\n",
            "8/8 [==============================] - 1s 81ms/step - loss: nan - accuracy: 0.5547 - val_loss: nan - val_accuracy: 0.5000\n",
            "Epoch 53/2000\n",
            "7/8 [=========================>....] - ETA: 0s - loss: nan - accuracy: 0.5610\n",
            "Epoch 53: accuracy did not improve from 0.55474\n",
            "8/8 [==============================] - 1s 82ms/step - loss: nan - accuracy: 0.5547 - val_loss: nan - val_accuracy: 0.5000\n",
            "Epoch 54/2000\n",
            "7/8 [=========================>....] - ETA: 0s - loss: nan - accuracy: 0.5562\n",
            "Epoch 54: accuracy did not improve from 0.55474\n",
            "8/8 [==============================] - 1s 84ms/step - loss: nan - accuracy: 0.5547 - val_loss: nan - val_accuracy: 0.5000\n",
            "Epoch 55/2000\n",
            "7/8 [=========================>....] - ETA: 0s - loss: nan - accuracy: 0.5581\n",
            "Epoch 55: accuracy did not improve from 0.55474\n",
            "8/8 [==============================] - 1s 80ms/step - loss: nan - accuracy: 0.5547 - val_loss: nan - val_accuracy: 0.5000\n",
            "Epoch 56/2000\n",
            "7/8 [=========================>....] - ETA: 0s - loss: nan - accuracy: 0.5571\n",
            "Epoch 56: accuracy did not improve from 0.55474\n",
            "8/8 [==============================] - 1s 83ms/step - loss: nan - accuracy: 0.5547 - val_loss: nan - val_accuracy: 0.5000\n",
            "Epoch 57/2000\n",
            "7/8 [=========================>....] - ETA: 0s - loss: nan - accuracy: 0.5533\n",
            "Epoch 57: accuracy did not improve from 0.55474\n",
            "8/8 [==============================] - 1s 81ms/step - loss: nan - accuracy: 0.5547 - val_loss: nan - val_accuracy: 0.5000\n",
            "Epoch 58/2000\n",
            "7/8 [=========================>....] - ETA: 0s - loss: nan - accuracy: 0.5600\n",
            "Epoch 58: accuracy did not improve from 0.55474\n",
            "8/8 [==============================] - 1s 81ms/step - loss: nan - accuracy: 0.5547 - val_loss: nan - val_accuracy: 0.5000\n",
            "Epoch 59/2000\n",
            "7/8 [=========================>....] - ETA: 0s - loss: nan - accuracy: 0.5610\n",
            "Epoch 59: accuracy did not improve from 0.55474\n",
            "8/8 [==============================] - 1s 83ms/step - loss: nan - accuracy: 0.5547 - val_loss: nan - val_accuracy: 0.5000\n",
            "Epoch 60/2000\n",
            "7/8 [=========================>....] - ETA: 0s - loss: nan - accuracy: 0.5552\n",
            "Epoch 60: accuracy did not improve from 0.55474\n",
            "8/8 [==============================] - 1s 81ms/step - loss: nan - accuracy: 0.5547 - val_loss: nan - val_accuracy: 0.5000\n",
            "Epoch 61/2000\n",
            "7/8 [=========================>....] - ETA: 0s - loss: nan - accuracy: 0.5552\n",
            "Epoch 61: accuracy did not improve from 0.55474\n",
            "8/8 [==============================] - 1s 82ms/step - loss: nan - accuracy: 0.5547 - val_loss: nan - val_accuracy: 0.5000\n",
            "Epoch 62/2000\n",
            "7/8 [=========================>....] - ETA: 0s - loss: nan - accuracy: 0.5610\n",
            "Epoch 62: accuracy did not improve from 0.55474\n",
            "8/8 [==============================] - 1s 81ms/step - loss: nan - accuracy: 0.5547 - val_loss: nan - val_accuracy: 0.5000\n",
            "Epoch 63/2000\n",
            "7/8 [=========================>....] - ETA: 0s - loss: nan - accuracy: 0.5514\n",
            "Epoch 63: accuracy did not improve from 0.55474\n",
            "8/8 [==============================] - 1s 79ms/step - loss: nan - accuracy: 0.5547 - val_loss: nan - val_accuracy: 0.5000\n",
            "Epoch 64/2000\n",
            "7/8 [=========================>....] - ETA: 0s - loss: nan - accuracy: 0.5495\n",
            "Epoch 64: accuracy did not improve from 0.55474\n",
            "8/8 [==============================] - 1s 81ms/step - loss: nan - accuracy: 0.5547 - val_loss: nan - val_accuracy: 0.5000\n",
            "Epoch 65/2000\n",
            "7/8 [=========================>....] - ETA: 0s - loss: nan - accuracy: 0.5533\n",
            "Epoch 65: accuracy did not improve from 0.55474\n",
            "8/8 [==============================] - 1s 81ms/step - loss: nan - accuracy: 0.5547 - val_loss: nan - val_accuracy: 0.5000\n",
            "Epoch 66/2000\n",
            "8/8 [==============================] - ETA: 0s - loss: nan - accuracy: 0.5547\n",
            "Epoch 66: accuracy did not improve from 0.55474\n",
            "8/8 [==============================] - 1s 84ms/step - loss: nan - accuracy: 0.5547 - val_loss: nan - val_accuracy: 0.5000\n",
            "Epoch 67/2000\n",
            "7/8 [=========================>....] - ETA: 0s - loss: nan - accuracy: 0.5495\n",
            "Epoch 67: accuracy did not improve from 0.55474\n",
            "8/8 [==============================] - 1s 79ms/step - loss: nan - accuracy: 0.5547 - val_loss: nan - val_accuracy: 0.5000\n",
            "Epoch 68/2000\n",
            "7/8 [=========================>....] - ETA: 0s - loss: nan - accuracy: 0.5600\n",
            "Epoch 68: accuracy did not improve from 0.55474\n",
            "8/8 [==============================] - 1s 80ms/step - loss: nan - accuracy: 0.5547 - val_loss: nan - val_accuracy: 0.5000\n",
            "Epoch 69/2000\n",
            "7/8 [=========================>....] - ETA: 0s - loss: nan - accuracy: 0.5552\n",
            "Epoch 69: accuracy did not improve from 0.55474\n",
            "8/8 [==============================] - 1s 83ms/step - loss: nan - accuracy: 0.5547 - val_loss: nan - val_accuracy: 0.5000\n",
            "Epoch 70/2000\n",
            "8/8 [==============================] - ETA: 0s - loss: nan - accuracy: 0.5547\n",
            "Epoch 70: accuracy did not improve from 0.55474\n",
            "8/8 [==============================] - 1s 85ms/step - loss: nan - accuracy: 0.5547 - val_loss: nan - val_accuracy: 0.5000\n",
            "Epoch 71/2000\n",
            "7/8 [=========================>....] - ETA: 0s - loss: nan - accuracy: 0.5590\n",
            "Epoch 71: accuracy did not improve from 0.55474\n",
            "8/8 [==============================] - 1s 79ms/step - loss: nan - accuracy: 0.5547 - val_loss: nan - val_accuracy: 0.5000\n",
            "Epoch 72/2000\n",
            "7/8 [=========================>....] - ETA: 0s - loss: nan - accuracy: 0.5571\n",
            "Epoch 72: accuracy did not improve from 0.55474\n",
            "8/8 [==============================] - 1s 84ms/step - loss: nan - accuracy: 0.5547 - val_loss: nan - val_accuracy: 0.5000\n",
            "Epoch 73/2000\n",
            "7/8 [=========================>....] - ETA: 0s - loss: nan - accuracy: 0.5562\n",
            "Epoch 73: accuracy did not improve from 0.55474\n",
            "8/8 [==============================] - 1s 82ms/step - loss: nan - accuracy: 0.5547 - val_loss: nan - val_accuracy: 0.5000\n",
            "Epoch 74/2000\n",
            "7/8 [=========================>....] - ETA: 0s - loss: nan - accuracy: 0.5590\n",
            "Epoch 74: accuracy did not improve from 0.55474\n",
            "8/8 [==============================] - 1s 80ms/step - loss: nan - accuracy: 0.5547 - val_loss: nan - val_accuracy: 0.5000\n",
            "Epoch 75/2000\n",
            "7/8 [=========================>....] - ETA: 0s - loss: nan - accuracy: 0.5524\n",
            "Epoch 75: accuracy did not improve from 0.55474\n",
            "8/8 [==============================] - 1s 82ms/step - loss: nan - accuracy: 0.5547 - val_loss: nan - val_accuracy: 0.5000\n",
            "Epoch 76/2000\n",
            "7/8 [=========================>....] - ETA: 0s - loss: nan - accuracy: 0.5505\n",
            "Epoch 76: accuracy did not improve from 0.55474\n",
            "8/8 [==============================] - 1s 80ms/step - loss: nan - accuracy: 0.5547 - val_loss: nan - val_accuracy: 0.5000\n",
            "Epoch 77/2000\n",
            "7/8 [=========================>....] - ETA: 0s - loss: nan - accuracy: 0.5552\n",
            "Epoch 77: accuracy did not improve from 0.55474\n",
            "8/8 [==============================] - 1s 78ms/step - loss: nan - accuracy: 0.5547 - val_loss: nan - val_accuracy: 0.5000\n",
            "Epoch 78/2000\n",
            "7/8 [=========================>....] - ETA: 0s - loss: nan - accuracy: 0.5552\n",
            "Epoch 78: accuracy did not improve from 0.55474\n",
            "8/8 [==============================] - 1s 82ms/step - loss: nan - accuracy: 0.5547 - val_loss: nan - val_accuracy: 0.5000\n",
            "Epoch 79/2000\n",
            "7/8 [=========================>....] - ETA: 0s - loss: nan - accuracy: 0.5524\n",
            "Epoch 79: accuracy did not improve from 0.55474\n",
            "8/8 [==============================] - 1s 82ms/step - loss: nan - accuracy: 0.5547 - val_loss: nan - val_accuracy: 0.5000\n",
            "Epoch 80/2000\n",
            "7/8 [=========================>....] - ETA: 0s - loss: nan - accuracy: 0.5533\n",
            "Epoch 80: accuracy did not improve from 0.55474\n",
            "8/8 [==============================] - 1s 82ms/step - loss: nan - accuracy: 0.5547 - val_loss: nan - val_accuracy: 0.5000\n",
            "Epoch 81/2000\n",
            "7/8 [=========================>....] - ETA: 0s - loss: nan - accuracy: 0.5581\n",
            "Epoch 81: accuracy did not improve from 0.55474\n",
            "8/8 [==============================] - 1s 83ms/step - loss: nan - accuracy: 0.5547 - val_loss: nan - val_accuracy: 0.5000\n",
            "Epoch 82/2000\n",
            "7/8 [=========================>....] - ETA: 0s - loss: nan - accuracy: 0.5533\n",
            "Epoch 82: accuracy did not improve from 0.55474\n",
            "8/8 [==============================] - 1s 80ms/step - loss: nan - accuracy: 0.5547 - val_loss: nan - val_accuracy: 0.5000\n",
            "Epoch 83/2000\n",
            "7/8 [=========================>....] - ETA: 0s - loss: nan - accuracy: 0.5600\n",
            "Epoch 83: accuracy did not improve from 0.55474\n",
            "8/8 [==============================] - 1s 84ms/step - loss: nan - accuracy: 0.5547 - val_loss: nan - val_accuracy: 0.5000\n",
            "Epoch 84/2000\n",
            "7/8 [=========================>....] - ETA: 0s - loss: nan - accuracy: 0.5600\n",
            "Epoch 84: accuracy did not improve from 0.55474\n",
            "8/8 [==============================] - 1s 87ms/step - loss: nan - accuracy: 0.5547 - val_loss: nan - val_accuracy: 0.5000\n",
            "Epoch 85/2000\n",
            "7/8 [=========================>....] - ETA: 0s - loss: nan - accuracy: 0.5571\n",
            "Epoch 85: accuracy did not improve from 0.55474\n",
            "8/8 [==============================] - 1s 79ms/step - loss: nan - accuracy: 0.5547 - val_loss: nan - val_accuracy: 0.5000\n",
            "Epoch 86/2000\n",
            "7/8 [=========================>....] - ETA: 0s - loss: nan - accuracy: 0.5495\n",
            "Epoch 86: accuracy did not improve from 0.55474\n",
            "8/8 [==============================] - 1s 86ms/step - loss: nan - accuracy: 0.5547 - val_loss: nan - val_accuracy: 0.5000\n",
            "Epoch 87/2000\n",
            "8/8 [==============================] - ETA: 0s - loss: nan - accuracy: 0.5547\n",
            "Epoch 87: accuracy did not improve from 0.55474\n",
            "8/8 [==============================] - 1s 83ms/step - loss: nan - accuracy: 0.5547 - val_loss: nan - val_accuracy: 0.5000\n",
            "Epoch 88/2000\n",
            "3/8 [==========>...................] - ETA: 0s - loss: nan - accuracy: 0.5400"
          ]
        }
      ],
      "source": [
        "filepath = '/content/drive/MyDrive/Model_DE/Model.hdf5'\n",
        " \n",
        "checkpoint = [tf.keras.callbacks.ModelCheckpoint(filepath, monitor='accuracy', mode='max', save_best_only=True, Save_weights_only = False, verbose = 1), \n",
        "              tf.keras.callbacks.EarlyStopping(monitor='accuracy', patience=225, verbose =2)]\n",
        "\n",
        "output_nodes = Y2.shape[1]\n",
        "print(output_nodes)\n",
        "model = tf.keras.Sequential([\n",
        "                             tf.keras.layers.Dense(1764, activation='relu', input_shape=(1764,)),\n",
        "                             tf.keras.layers.Dense(512, activation='relu'),\n",
        "                             tf.keras.layers.Dense(512, activation='relu'),\n",
        "                             tf.keras.layers.Dense(output_nodes, activation= 'Softmax')])\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.8), loss=tf.keras.losses.CategoricalCrossentropy(from_logits = False), metrics=['accuracy'])\n",
        "hist = model.fit(X_train, Y2_train, epochs= 2000, callbacks=[checkpoint],validation_data=(X_val, Y2_val), batch_size= 150)\n",
        "model.evaluate(X_test, Y2_test)\n",
        " \n",
        "Y2_train_predict = np.round(model.predict(X_train))\n",
        "Y2_train_l = tf.argmax(Y2_train, axis = 1)\n",
        "Y2_train_predict_l = tf.argmax(Y2_train_predict, axis =1)\n",
        "import sklearn.metrics as skm\n",
        "cm = skm.multilabel_confusion_matrix(Y2_train_l, Y2_train_predict_l)\n",
        "print(cm)\n",
        "print( skm.classification_report(Y2_train_l, Y2_train_predict_l))\n",
        " \n",
        "train_acc = max(hist.history['accuracy'])\n",
        "val_acc = max(hist.history['val_accuracy'])\n",
        "train_loss = min(hist.history['loss'])\n",
        "val_loss = min(hist.history['val_loss'])\n",
        "print('Training Accuracy is')\n",
        "print(train_acc)\n",
        "print('Validation Accuracy is')\n",
        "print(val_acc)\n",
        "print('Training loss is')\n",
        "print(train_loss)\n",
        "print('Validation loss is')\n",
        "print(val_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5hHT-inrRYAY",
        "outputId": "5ac0eb6b-0986-4ee7-ce0c-f31cb0427909"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[1.71530455e-01 8.16830218e-01 6.65873110e-01 3.60201508e-01\n",
            "  1.99705362e-04 2.29805708e-04 6.58282876e-01 3.73521060e-01\n",
            "  2.51263380e-04 2.94816494e-03 1.98728012e-05 8.19228371e-05\n",
            "  3.87079358e-01 4.11924448e-05 2.22253799e-03 4.13147867e-01\n",
            "  2.75138021e-03 2.40655124e-01 8.58038664e-04 1.06510520e-03\n",
            "  6.77317381e-04 7.55854368e-01 2.60028243e-03 2.05155629e-05\n",
            "  2.05650061e-01 1.74760818e-04 9.11428579e-05 9.99983191e-01\n",
            "  7.51295805e-01 2.40557075e-01 8.49283970e-05 2.69323587e-04\n",
            "  1.92046165e-04 1.62856122e-05 1.26387904e-05]\n",
            " [4.54753081e-06 9.99998808e-01 2.39379663e-08 9.99999285e-01\n",
            "  1.53970058e-21 4.55224325e-17 9.99996603e-01 1.51708662e-06\n",
            "  5.24412413e-15 5.02116237e-10 1.25044635e-20 1.46101262e-18\n",
            "  9.99990106e-01 7.79245744e-18 7.07244983e-12 3.66711191e-07\n",
            "  1.82847085e-10 8.12716561e-09 7.39361304e-14 1.21551515e-14\n",
            "  1.19079825e-18 2.98875129e-05 3.23215318e-05 9.99941826e-01\n",
            "  7.37296613e-11 6.56344163e-12 6.15678307e-15 1.00000000e+00\n",
            "  1.00000000e+00 1.53888472e-13 3.61246241e-11 9.01885530e-16\n",
            "  1.14556944e-16 1.52727656e-20 9.81258705e-20]\n",
            " [3.42680305e-01 6.34343863e-01 1.69472158e-01 8.15307021e-01\n",
            "  5.90914424e-05 4.11806434e-01 6.34289920e-01 1.38047338e-03\n",
            "  2.29153961e-01 3.48985195e-04 5.19861885e-07 1.93520691e-06\n",
            "  6.69557273e-01 8.23437313e-06 7.68065453e-04 2.12317705e-03\n",
            "  2.36512691e-01 2.21937895e-04 3.01985765e-05 1.70704807e-05\n",
            "  3.72480190e-06 9.98224854e-01 1.10560656e-03 1.57884938e-06\n",
            "  3.36557627e-04 3.61995008e-05 5.05076196e-06 9.99999166e-01\n",
            "  9.98685718e-01 8.48260825e-05 2.03863328e-05 1.02364880e-04\n",
            "  3.85187559e-06 6.84045801e-07 5.12431711e-07]\n",
            " [9.99811649e-01 2.00182199e-04 3.06243419e-06 9.99999523e-01\n",
            "  7.72371750e-12 2.09958231e-13 9.99995887e-01 2.67918745e-06\n",
            "  1.61381835e-12 3.98116609e-11 4.45538043e-14 9.99906540e-01\n",
            "  3.17183731e-06 7.03605565e-06 1.64753365e-05 7.77883251e-05\n",
            "  1.09948205e-11 8.25644165e-05 1.07556446e-11 7.03483203e-16\n",
            "  9.34754390e-14 9.99879777e-01 1.71687007e-05 2.63562663e-13\n",
            "  2.86006916e-08 4.95633753e-13 1.48591805e-14 1.00000000e+00\n",
            "  6.21746585e-05 9.99919951e-01 3.70467573e-10 7.63509589e-10\n",
            "  3.10840307e-12 3.59809161e-14 3.80825335e-13]\n",
            " [4.46656406e-01 5.22483826e-01 2.29489803e-03 9.96411085e-01\n",
            "  3.36229801e-04 7.41027834e-05 9.97405589e-01 4.51117754e-04\n",
            "  7.81896524e-05 2.69114971e-04 3.22461756e-06 6.67199565e-05\n",
            "  4.14112210e-03 9.37834848e-05 2.59572268e-03 4.11111951e-01\n",
            "  5.10012984e-01 6.08175993e-04 5.00808128e-05 9.53335621e-06\n",
            "  1.92915468e-05 9.94918644e-01 1.12861395e-03 7.12975680e-06\n",
            "  5.47826290e-04 5.88703597e-06 6.31380462e-05 9.99994755e-01\n",
            "  3.76868248e-01 2.41607428e-04 2.23487616e-04 5.30743122e-01\n",
            "  1.34468079e-04 3.14634644e-06 1.00303287e-05]]\n",
            "[[0. 1. 1. ... 0. 0. 0.]\n",
            " [0. 1. 0. ... 0. 0. 0.]\n",
            " [0. 1. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 1. 1. ... 0. 0. 0.]\n",
            " [0. 1. 0. ... 0. 0. 0.]\n",
            " [0. 1. 0. ... 0. 0. 0.]]\n",
            "  METHANOL ACETONITRILE WATER                          BUFFER OTHER    PHASE  \\\n",
            "0       No          Yes    No  Potassium dihydrogen phosphate    No  Reverse   \n",
            "1      Yes           No    No                Phosphate buffer    No  Reverse   \n",
            "2       No          Yes    No  Potassium dihydrogen phosphate    No  Reverse   \n",
            "3      Yes           No    No  Potassium dihydrogen phosphate    No  Reverse   \n",
            "4       No          Yes    No  Potassium dihydrogen phosphate    No  Reverse   \n",
            "\n",
            "  COLUMN  \n",
            "0    C-8  \n",
            "1   C-18  \n",
            "2   C-18  \n",
            "3    C-8  \n",
            "4   C-18   [['Yes' 'No' 'No' None 'No' 'Reverse' 'C-18']\n",
            " ['Yes' 'Yes' 'No' 'No' 'Potassium dihydrogen phosphate and TEA'\n",
            "  'Reverse' 'C-18']\n",
            " ['Yes' 'Yes' 'No' 'No' 'No' 'Reverse' 'C-18']\n",
            " ['No' 'Yes' 'No' 'Disodium hydrogen phosphate' 'No' 'Reverse' 'C-8']\n",
            " ['Yes' 'Yes' 'No' 'Sodium acetate' 'No' 'Reverse' 'InertsilODS-3V']\n",
            " ['Yes' 'No' 'No' None 'No' 'Reverse' 'C-18']\n",
            " ['No' 'Yes' 'No' 'Sodium dihydrogen phosphate' 'No' 'Reverse' 'C-18']\n",
            " ['Yes' 'Yes' 'No' 'Potassium dihydrogen phosphate' 'No' 'Reverse' 'C-18']\n",
            " ['No' 'Yes' 'No' 'Phosphate buffer' 'No' 'Reverse' 'C-18']\n",
            " ['Yes' 'No' 'No' None 'NaOH' 'Reverse' 'C-18']\n",
            " ['Yes' 'Yes' 'No' 'No' None 'Reverse' 'C-18']\n",
            " ['Yes' 'No' 'No' 'No' None 'Reverse' 'C-18']\n",
            " ['Yes' 'No' 'No' None 'No' 'Reverse' 'C-18']\n",
            " ['Yes' 'No' 'No' 'Potassium dihydrogen phosphate' 'No' 'Reverse' 'C-18']\n",
            " ['No' 'Yes' 'Yes' 'No' 'Ortho Phosphoric acid' 'Reverse' 'C-18']\n",
            " ['Yes' 'No' 'Yes' 'No' 'Ortho Phosphoric acid' 'Reverse' 'C-18']\n",
            " ['Yes' 'Yes' 'No' 'No' 'No' 'Reverse' 'C-18']\n",
            " ['Yes' 'No' 'Yes' 'No' 'Acetic acid' 'Reverse' 'C-18']\n",
            " ['No' 'Yes' 'No' None None 'Reverse' 'C-18']\n",
            " ['No' 'Yes' 'No' 'Potassium dihydrogen phosphate'\n",
            "  'Ortho Phosphoric acid' 'Reverse' 'C-18']\n",
            " ['Yes' 'No' 'Yes' 'No' 'Acetic acid' 'Reverse' 'C-18']\n",
            " ['Yes' 'No' 'No' None 'No' 'Reverse' 'C-18']\n",
            " ['Yes' 'No' 'No' None 'NaOH' 'Reverse' 'C-18']\n",
            " ['No' 'Yes' 'No' 'Phosphate buffer' 'No' 'Reverse' 'C-18']\n",
            " ['Yes' 'No' 'No' None 'No' 'Reverse' 'C-18']\n",
            " ['Yes' 'Yes' 'No' 'Potassium dihydrogen phosphate' 'No' 'Reverse' 'C-18']\n",
            " ['Yes' 'No' 'No' None 'No' 'Reverse' 'C-18']\n",
            " ['No' 'Yes' 'No' 'Sodium dihydrogen phosphate' 'No' 'Reverse' 'C-18']\n",
            " ['Yes' 'No' 'No' 'No' None 'Reverse' 'C-18']\n",
            " ['Yes' 'No' 'No' 'Potassium dihydrogen phosphate' 'No' 'Reverse' 'C-18']\n",
            " ['Yes' 'Yes' 'Yes' 'No' 'No' 'Reverse' 'C-18']\n",
            " ['No' 'Yes' 'No' 'Phosphate buffer' 'No' 'Reverse' 'C-18']\n",
            " ['No' 'Yes' 'No' 'Phosphate buffer' 'No' 'Reverse' 'C-18']\n",
            " ['Yes' 'No' 'Yes' 'No' 'No' 'Reverse' 'C-18']\n",
            " ['Yes' 'Yes' 'No' 'No' None 'Reverse' 'C-18']\n",
            " ['Yes' 'Yes' 'No' None None 'Reverse' 'PhenomenexLuna']\n",
            " ['Yes' 'Yes' 'No' 'Ortho Phosphoric acid' 'No' 'Reverse' 'C-8']\n",
            " ['Yes' 'Yes' 'No' None None 'Reverse' 'PhenomenexLuna']\n",
            " ['No' 'Yes' 'No' None None 'Reverse' 'C-18']\n",
            " ['Yes' 'Yes' 'No' 'No' None 'Reverse' 'InertsilODS-3']\n",
            " ['No' 'Yes' '     Yes' 'Potassium dihydrogen phosphate' 'No' 'Reverse'\n",
            "  'C-18']\n",
            " ['Yes' 'Yes' 'No' 'No' 'Ortho Phosphoric acid' 'Reverse' 'C-18']\n",
            " ['No' 'Yes' 'No' None None 'Reverse' 'C-18']\n",
            " ['No' 'Yes' 'Yes' 'No' 'No' 'Reverse' 'C-18']\n",
            " ['Yes' 'Yes' 'No' 'No' None 'Reverse' 'InertsilODS-3']\n",
            " ['No' 'Yes' 'No' None None 'Reverse' 'C-18']\n",
            " ['Yes' 'Yes' 'No' None 'No' 'Reverse' 'C-18']\n",
            " ['Yes' 'No' 'No' 'No' None 'Reverse' 'C-18']\n",
            " ['Yes' 'Yes' 'No' 'Potassium dihydrogen phosphate' 'No' 'Reverse' 'C-18']\n",
            " ['No' 'Yes' 'No' None None 'Reverse' 'C-18']\n",
            " ['No' 'Yes' 'Yes' 'No' 'Trifluroacetic acid' 'Reverse' 'C-18']\n",
            " ['Yes' 'Yes' 'No' 'No' 'No' 'Reverse' 'C-18']\n",
            " ['Yes' 'No' 'No' 'No' None 'Reverse' 'C-18']\n",
            " ['No' 'Yes' 'No' 'Potassium dihydrogen phosphate' 'No' 'Reverse' 'C-18']\n",
            " ['Yes' 'Yes' 'No' 'Phosphate buffer' 'No' 'Reverse' 'C-18']\n",
            " ['Yes' 'Yes' 'No' 'No' None 'Reverse' 'C-18']\n",
            " ['Yes' 'No' 'No' 'Potassium dihydrogen phosphate' 'No' 'Reverse' 'C-8']\n",
            " ['Yes' 'Yes' 'No' 'Phosphate buffer' 'No' 'Reverse' 'C-18']\n",
            " ['No' 'Yes' 'No' 'Potassium dihydrogen phosphate'\n",
            "  'Ortho Phosphoric acid' 'Reverse' 'C-18']\n",
            " ['No' 'Yes' 'No' 'Potassium dihydrogen phosphate' 'No' 'Reverse' 'C-18']\n",
            " ['Yes' 'No' 'No' 'Sodium acetate' 'No' 'Reverse' 'C-18']\n",
            " ['Yes' 'Yes' 'No' None 'No' 'Reverse' 'C-18']\n",
            " ['Yes' 'Yes' 'No' 'No' 'No' 'Reverse' 'C-18']\n",
            " ['Yes' 'Yes' 'No' 'No' 'No' 'Reverse' 'C-18']\n",
            " ['No' 'Yes' 'No' 'Phosphate buffer' 'No' 'Reverse' 'C-18']\n",
            " ['No' 'Yes' 'No' None None 'Reverse' 'C-18']\n",
            " ['Yes' 'No' 'No' 'Potassium dihydrogen phosphate' 'No' 'Reverse' 'C-18']\n",
            " ['Yes' 'No' 'No' 'Ammonium acetate ' 'No' 'Reverse' 'C-18']\n",
            " ['Yes' 'Yes' 'No' 'Sodium acetate' 'No' 'Reverse' 'InertsilODS-3V']\n",
            " ['Yes' 'Yes' 'No' 'No' None 'Reverse' 'C-18']] (70, 7)\n"
          ]
        }
      ],
      "source": [
        "t1 = model.predict(X_train[0:5,:])\n",
        "print(t1)\n",
        " \n",
        "t = np.round(model.predict(X_train))\n",
        "print(t)\n",
        " \n",
        "Y_prediction = enc.inverse_transform(t)\n",
        "print(Y1.head(),Y_prediction, Y_prediction.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wn49FyCQWw6R"
      },
      "outputs": [],
      "source": [
        "X.to_csv('Drug_1.csv')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMb+CeABw+eR/+DybkWsQUY",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}